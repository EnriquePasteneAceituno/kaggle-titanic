{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üö¢ EPA Titanic KNN ‚Äî Feature Engineering\nKNN con ingenier√≠a de atributos (FamilySize, IsAlone, Title, CabinKnown, FarePerPerson, TicketGroupSize) + preprocesamiento y Grid Search.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:45:38.928769Z","iopub.execute_input":"2025-08-29T01:45:38.929938Z","iopub.status.idle":"2025-08-29T01:45:38.936744Z","shell.execute_reply.started":"2025-08-29T01:45:38.929907Z","shell.execute_reply":"2025-08-29T01:45:38.935783Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# üì• Celda 2 ‚Äî Carga de datos (train y test)\nLeemos los CSV oficiales desde `/kaggle/input/titanic/` y validamos dimensiones.","metadata":{}},{"cell_type":"code","source":"# Importamos pandas para manejo de DataFrames\nimport pandas as pd\n\n# Definimos rutas de los archivos provistos por la competici√≥n\ntrain_path = \"/kaggle/input/titanic/train.csv\"   # ruta de train.csv\ntest_path  = \"/kaggle/input/titanic/test.csv\"    # ruta de test.csv\n\n# Cargamos los datasets en memoria\ntrain_df = pd.read_csv(train_path)               # DataFrame de entrenamiento\ntest_df  = pd.read_csv(test_path)                # DataFrame de test (sin Survived)\n\n# Mostramos formas para confirmar tama√±o esperado\nprint(\"Shape train:\", train_df.shape)            # deber√≠a ser (891, 12)\nprint(\"Shape test :\", test_df.shape)             # deber√≠a ser (418, 11)\n\n# Vista r√°pida de columnas relevantes\ntrain_df.head()                                  # primeras filas para inspecci√≥n visual","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:45:53.231755Z","iopub.execute_input":"2025-08-29T01:45:53.232069Z","iopub.status.idle":"2025-08-29T01:45:53.257296Z","shell.execute_reply.started":"2025-08-29T01:45:53.232041Z","shell.execute_reply":"2025-08-29T01:45:53.256397Z"}},"outputs":[{"name":"stdout","text":"Shape train: (891, 12)\nShape test : (418, 11)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# üîé Celda 3 ‚Äî EDA breve (faltantes y balance de Survived)\nRevisamos cu√°ntos valores faltantes hay por columna en train y test, \ny verificamos la distribuci√≥n de la variable objetivo `Survived`.","metadata":{}},{"cell_type":"code","source":"# Mostramos las columnas disponibles en el dataset de entrenamiento\nprint(\"Columnas en train:\", train_df.columns.tolist())  \n\n# Revisamos cu√°ntos valores faltantes (NaN) hay por columna en train\nprint(\"\\nFaltantes en train:\")\nprint(train_df.isna().sum())  \n\n# Revisamos cu√°ntos valores faltantes (NaN) hay por columna en test\nprint(\"\\nFaltantes en test:\")\nprint(test_df.isna().sum())  \n\n# Verificamos la distribuci√≥n de la variable objetivo Survived (0 = no, 1 = s√≠)\nprint(\"\\nDistribuci√≥n de Survived en train:\")\nprint(train_df[\"Survived\"].value_counts(normalize=True))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:47:48.027177Z","iopub.execute_input":"2025-08-29T01:47:48.028115Z","iopub.status.idle":"2025-08-29T01:47:48.044211Z","shell.execute_reply.started":"2025-08-29T01:47:48.028082Z","shell.execute_reply":"2025-08-29T01:47:48.043462Z"}},"outputs":[{"name":"stdout","text":"Columnas en train: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nFaltantes en train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nFaltantes en test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\nDistribuci√≥n de Survived en train:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# üß± Celda 4 ‚Äî Definici√≥n de variables base y objetivo\nSeparamos las columnas de entrada (`X`) y la variable objetivo (`y`) para el entrenamiento.\nAdem√°s, retenemos el `PassengerId` del test para construir luego el archivo de submission.","metadata":{}},{"cell_type":"code","source":"# Definimos columnas num√©ricas base (antes de aplicar feature engineering)\nbase_num_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n\n# Definimos columnas categ√≥ricas base\nbase_cat_features = [\"Sex\", \"Embarked\"]\n\n# Construimos X con las columnas base desde train\nX = train_df[base_num_features + base_cat_features].copy()\n\n# Definimos el vector objetivo (y = Survived) y lo convertimos a entero\ny = train_df[\"Survived\"].astype(int)\n\n# Guardamos PassengerId del test (necesario para el submission final)\ntest_passenger_id = test_df[\"PassengerId\"].copy()\n\n# Construimos X_test con las mismas columnas base desde test\nX_test = test_df[base_num_features + base_cat_features].copy()\n\n# Vista previa de las primeras filas de X\nX.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:51:13.448868Z","iopub.execute_input":"2025-08-29T01:51:13.449618Z","iopub.status.idle":"2025-08-29T01:51:13.470410Z","shell.execute_reply.started":"2025-08-29T01:51:13.449591Z","shell.execute_reply":"2025-08-29T01:51:13.469436Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    Age  SibSp  Parch     Fare  Pclass     Sex Embarked\n0  22.0      1      0   7.2500       3    male        S\n1  38.0      1      0  71.2833       1  female        C\n2  26.0      0      0   7.9250       3  female        S\n3  35.0      1      0  53.1000       1  female        S\n4  35.0      0      0   8.0500       3    male        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>female</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>3</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# üß™ Celda 5 ‚Äî Ingenier√≠a de atributos (FunctionTransformer)\nCreamos nuevas features dentro de un `Pipeline`:  \n- `FamilySize = SibSp + Parch + 1`  \n- `IsAlone` (1 si viaja solo)  \n- `Title` (extra√≠do de `Name`)  \n- `CabinKnown` (1 si `Cabin` no es NaN)  \n- `FarePerPerson = Fare / FamilySize`  \n- `TicketGroupSize` (tama√±o de grupo por `Ticket`)  \n\n> Nota: Para que el transformador pueda extraer t√≠tulos y usar `Ticket/Cabin`, **a√±adimos temporalmente** esas columnas a `X` y `X_test`. Luego, el `ColumnTransformer` las descartar√° (no est√°n en las listas finales de features).","metadata":{}},{"cell_type":"code","source":"# --- Aseguramos que X y X_test incluyan columnas necesarias para FE (Name, Ticket, Cabin) ---\nextra_cols = [\"Name\", \"Ticket\", \"Cabin\"]                                # columnas auxiliares para FE\nfor col in extra_cols:\n    if col not in X.columns and col in train_df.columns:\n        X[col] = train_df.loc[X.index, col]                             # a√±adimos desde train_df por √≠ndice\n    if col not in X_test.columns and col in test_df.columns:\n        X_test[col] = test_df.loc[X_test.index, col]                    # a√±adimos desde test_df por √≠ndice\n\n# --- Definimos el transformador de FE ---\nfrom sklearn.preprocessing import FunctionTransformer\nimport numpy as np\nimport pandas as pd\n\ndef add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()                                                       # no modificar in-place\n\n    # FamilySize e IsAlone\n    df[\"FamilySize\"] = df[\"SibSp\"].fillna(0) + df[\"Parch\"].fillna(0) + 1\n    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n\n    # Title (si existe Name)\n    if \"Name\" in df.columns:\n        titles = df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\")[0]            # texto entre la coma y el punto\n        titles = titles.replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n        common = {\"Mr\",\"Mrs\",\"Miss\",\"Master\",\"Dr\",\"Rev\",\"Col\",\"Major\",\"Lady\",\"Countess\",\"Jonkheer\",\"Don\",\"Dona\",\"Capt\",\"Sir\"}\n        titles = titles.where(titles.isin(list(common)), \"Other\")\n        df[\"Title\"] = titles.fillna(\"Other\")\n    else:\n        df[\"Title\"] = \"Other\"\n\n    # CabinKnown (si existe Cabin)\n    if \"Cabin\" in df.columns:\n        df[\"CabinKnown\"] = (~df[\"Cabin\"].isna()).astype(int)\n    else:\n        df[\"CabinKnown\"] = 0\n\n    # FarePerPerson\n    df[\"FarePerPerson\"] = (df[\"Fare\"].fillna(df[\"Fare\"].median())) / df[\"FamilySize\"].replace(0, 1)\n\n    # TicketGroupSize (si existe Ticket)\n    if \"Ticket\" in df.columns:\n        counts = df[\"Ticket\"].map(df[\"Ticket\"].value_counts())\n        df[\"TicketGroupSize\"] = counts.fillna(1).astype(int)\n    else:\n        df[\"TicketGroupSize\"] = 1\n\n    return df\n\n# Creamos el FunctionTransformer para usarlo en el Pipeline\nfeature_engineering = FunctionTransformer(add_engineered_features, validate=False)\n\nprint(\"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T01:56:34.528940Z","iopub.execute_input":"2025-08-29T01:56:34.529240Z","iopub.status.idle":"2025-08-29T01:56:35.121431Z","shell.execute_reply.started":"2025-08-29T01:56:34.529216Z","shell.execute_reply":"2025-08-29T01:56:35.120190Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido).\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# üßΩ Celda 6 ‚Äî Preprocesamiento por tipo de columna\nImputaci√≥n (mediana/moda), escalado (StandardScaler) y One-Hot para categ√≥ricas.\nIncluye las **features ingenierizadas** generadas en la Celda 5.","metadata":{}},{"cell_type":"code","source":"# Importamos las piezas necesarias para el preprocesamiento y el pipeline\nfrom sklearn.compose import ColumnTransformer                      # aplicar transformaciones por columnas\nfrom sklearn.pipeline import Pipeline                              # encadenar pasos\nfrom sklearn.impute import SimpleImputer                           # imputar NaN\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler    # one-hot y escalado\n\n# Definimos las columnas finales que usaremos DESPU√âS de la ingenier√≠a de features\n# (las columnas auxiliares Name/Ticket/Cabin NO se listan aqu√≠; no ser√°n usadas como features directas)\nnum_features = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\",  # base num√©ricas\n    \"FamilySize\", \"IsAlone\", \"FarePerPerson\",   # FE num√©ricas\n    \"TicketGroupSize\", \"CabinKnown\"             # FE num√©ricas/bool\n]\n\ncat_features = [\n    \"Sex\", \"Embarked\", \"Title\"                  # categ√≥ricas (Title viene de FE)\n]\n\n# Pipeline para columnas num√©ricas: imputar con mediana + escalar\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),  # NaN -> mediana (robusto a outliers)\n    (\"scaler\", StandardScaler())                    # requerido para distancias en KNN\n])\n\n# Pipeline para columnas categ√≥ricas: imputar con moda + One-Hot (denso)\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),             # NaN -> valor m√°s frecuente\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # sin warnings, ignora categor√≠as nuevas\n])\n\n# ColumnTransformer que aplica cada pipeline a su grupo de columnas\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_features),\n        (\"cat\", categorical_transformer, cat_features)\n    ],\n    remainder=\"drop\"  # descarta columnas no listadas (p. ej., Name/Ticket/Cabin auxiliares)\n)\n\n# Informaci√≥n √∫til para verificar\nprint(\"‚úÖ Preprocesamiento listo.\")\nprint(\"Num features:\", num_features)\nprint(\"Cat features:\", cat_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:02:53.545520Z","iopub.execute_input":"2025-08-29T02:02:53.546607Z","iopub.status.idle":"2025-08-29T02:02:54.066553Z","shell.execute_reply.started":"2025-08-29T02:02:53.546579Z","shell.execute_reply":"2025-08-29T02:02:54.065562Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Preprocesamiento listo.\nNum features: ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass', 'FamilySize', 'IsAlone', 'FarePerPerson', 'TicketGroupSize', 'CabinKnown']\nCat features: ['Sex', 'Embarked', 'Title']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# ü§ñ Celda 7 ‚Äî Pipeline completo (FE + Prepro + KNN) y validaci√≥n cruzada\nEncadenamos **ingenier√≠a de atributos ‚Üí preprocesamiento ‚Üí KNN** en un solo `Pipeline`\ny medimos el desempe√±o con **validaci√≥n cruzada estratificada (5 folds)** usando *accuracy*.","metadata":{}},{"cell_type":"code","source":"# Importamos el clasificador KNN y utilidades para validaci√≥n\nfrom sklearn.neighbors import KNeighborsClassifier                 # modelo KNN\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score  # CV estratificada\nimport numpy as np                                                  # operaciones num√©ricas\n\n# Definimos un KNN base como punto de partida (luego haremos Grid Search en la Celda 8)\nbase_knn = KNeighborsClassifier(\n    n_neighbors=7,        # k inicial razonable\n    weights=\"uniform\",    # todos los vecinos pesan igual (alternativa: \"distance\")\n    p=2                   # distancia Eucl√≠dea (p=1 ser√≠a Manhattan)\n)\n\n# Construimos el pipeline completo: Feature Engineering -> Preprocesamiento -> Modelo\npipe_knn = Pipeline(steps=[\n    (\"fe\", feature_engineering),   # a√±ade columnas ingenierizadas a partir de X\n    (\"pre\", preprocessor),         # imputaci√≥n, escalado y one-hot por tipo de columna\n    (\"knn\", base_knn)              # clasificador KNN\n])\n\n# Definimos validaci√≥n cruzada estratificada (mantiene proporci√≥n de clases)\ncv = StratifiedKFold(\n    n_splits=5,       # 5 folds\n    shuffle=True,     # baraja antes de dividir\n    random_state=42   # reproducibilidad\n)\n\n# Evaluamos el pipeline con accuracy mediante cross-validation\ncv_scores = cross_val_score(\n    estimator=pipe_knn,  # pipeline completo\n    X=X,                 # caracter√≠sticas (con columnas base; FE se aplica dentro del pipeline)\n    y=y,                 # variable objetivo\n    cv=cv,               # esquema de validaci√≥n\n    scoring=\"accuracy\",  # m√©trica oficial de la competici√≥n\n    n_jobs=-1            # usa todos los n√∫cleos disponibles\n)\n\n# Mostramos resultados por fold y resumen\nprint(\"Accuracy por fold:\", np.round(cv_scores, 4))                   # accuracies individuales\nprint(\"Accuracy promedio (CV):\", cv_scores.mean().round(4),           # promedio de accuracy\n      \"| Desv. std:\", cv_scores.std().round(4))                       # variabilidad entre folds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:12:37.153023Z","iopub.execute_input":"2025-08-29T02:12:37.153328Z","iopub.status.idle":"2025-08-29T02:12:39.338187Z","shell.execute_reply.started":"2025-08-29T02:12:37.153310Z","shell.execute_reply":"2025-08-29T02:12:39.336809Z"}},"outputs":[{"name":"stdout","text":"Accuracy por fold: [0.8324 0.8202 0.7528 0.8202 0.8202]\nAccuracy promedio (CV): 0.8092 | Desv. std: 0.0286\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# üîé Celda 8 ‚Äî Grid Search de KNN con Feature Engineering\nExploramos distintas combinaciones de hiperpar√°metros para KNN:  \n- `n_neighbors` (k: cantidad de vecinos)  \n- `weights` (uniforme vs. ponderado por distancia)  \n- `p` (1 = Manhattan, 2 = Eucl√≠dea)  \n\nEl objetivo es encontrar la configuraci√≥n que maximiza **accuracy** en validaci√≥n cruzada.\n","metadata":{}},{"cell_type":"code","source":"# Importamos GridSearchCV para b√∫squeda exhaustiva\nfrom sklearn.model_selection import GridSearchCV\n\n# Reconstruimos el pipeline (por claridad) incluyendo FE + Prepro + KNN\npipe_knn = Pipeline(steps=[\n    (\"fe\", feature_engineering),   # ingenier√≠a de atributos\n    (\"pre\", preprocessor),         # preprocesamiento\n    (\"knn\", KNeighborsClassifier())# KNN \"vac√≠o\" -> par√°metros definidos por grid\n])\n\n# Definimos la grilla de hiperpar√°metros a explorar\nparam_grid = {\n    \"knn__n_neighbors\": [3, 5, 7, 9, 11, 13, 15, 19, 25, 31],  # distintos valores de k\n    \"knn__weights\": [\"uniform\", \"distance\"],                   # peso uniforme o por distancia\n    \"knn__p\": [1, 2]                                           # distancia Manhattan (1) o Eucl√≠dea (2)\n}\n\n# Reutilizamos validaci√≥n cruzada estratificada\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Configuramos GridSearchCV\ngrid = GridSearchCV(\n    estimator=pipe_knn,          # pipeline completo\n    param_grid=param_grid,       # grilla de b√∫squeda\n    scoring=\"accuracy\",          # m√©trica oficial\n    cv=cv,                       # validaci√≥n cruzada\n    n_jobs=-1,                   # usar todos los cores disponibles\n    refit=True,                  # reentrena el mejor en todo el train\n    verbose=1                    # verboso para seguir el progreso\n)\n\n# Ejecutamos el grid search\ngrid.fit(X, y)\n\n# Reportamos los mejores resultados\nprint(\"üîù Mejor accuracy (CV):\", grid.best_score_.round(4))\nprint(\"üîß Mejores hiperpar√°metros:\", grid.best_params_)\n\n# Guardamos el mejor pipeline ya reentrenado\nbest_model = grid.best_estimator_\n\n# Mostramos los 5 mejores resultados del grid ordenados\nres = pd.DataFrame(grid.cv_results_).sort_values(\"mean_test_score\", ascending=False)\nres_top5 = res[[\"mean_test_score\",\"std_test_score\",\"param_knn__n_neighbors\",\"param_knn__weights\",\"param_knn__p\"]].head(5)\ndisplay(res_top5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:17:01.631675Z","iopub.execute_input":"2025-08-29T02:17:01.632020Z","iopub.status.idle":"2025-08-29T02:17:04.797652Z","shell.execute_reply.started":"2025-08-29T02:17:01.631991Z","shell.execute_reply":"2025-08-29T02:17:04.796954Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 40 candidates, totalling 200 fits\nüîù Mejor accuracy (CV): 0.8249\nüîß Mejores hiperpar√°metros: {'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'uniform'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    mean_test_score  std_test_score param_knn__n_neighbors param_knn__weights  \\\n20         0.824895        0.020994                     13            uniform   \n8          0.820394        0.023235                      7            uniform   \n32         0.819302        0.002380                     25            uniform   \n12         0.819289        0.014982                      9            uniform   \n28         0.818178        0.009186                     19            uniform   \n\n   param_knn__p  \n20            1  \n8             1  \n32            1  \n12            1  \n28            1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>param_knn__n_neighbors</th>\n      <th>param_knn__weights</th>\n      <th>param_knn__p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>0.824895</td>\n      <td>0.020994</td>\n      <td>13</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.820394</td>\n      <td>0.023235</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.819302</td>\n      <td>0.002380</td>\n      <td>25</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.819289</td>\n      <td>0.014982</td>\n      <td>9</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.818178</td>\n      <td>0.009186</td>\n      <td>19</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# üì§ Celda 9 ‚Äî Predicci√≥n final y creaci√≥n de `submission.csv`\nUsamos el **mejor pipeline** encontrado por GridSearchCV (`best_model`) para predecir en `test.csv`\ny generamos el archivo de env√≠o con las columnas `PassengerId` y `Survived` (418 filas).\n","metadata":{}},{"cell_type":"code","source":"# 1) Predicci√≥n en el set de test usando el mejor modelo del grid (ya reentrenado con refit=True)\ntest_preds = best_model.predict(X_test)          # predicciones binarias 0/1\ntest_preds = test_preds.astype(int)              # aseguramos tipo entero\n\n# 2) Construimos el DataFrame de submission con el formato oficial\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_passenger_id,           # IDs del test\n    \"Survived\": test_preds                      # predicciones\n})\n\n# 3) Chequeos de formato (defensivos)\nassert submission.shape[0] == 418, \"El submission debe tener exactamente 418 filas.\"\nassert list(submission.columns) == [\"PassengerId\", \"Survived\"], \"Las columnas deben ser exactamente PassengerId y Survived.\"\n\n# 4) Guardamos el CSV listo para subir a Kaggle\nsubmission.to_csv(\"submission.csv\", index=False)\n\n# 5) Confirmaci√≥n y vista previa\nprint(\"‚úÖ Archivo 'submission.csv' creado con\", submission.shape[0], \"filas.\")\nprint(submission.head())\nprint(\"\\nConteo predicciones:\", submission[\"Survived\"].value_counts().to_dict())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:25:08.598589Z","iopub.execute_input":"2025-08-29T02:25:08.599475Z","iopub.status.idle":"2025-08-29T02:25:08.685362Z","shell.execute_reply.started":"2025-08-29T02:25:08.599448Z","shell.execute_reply":"2025-08-29T02:25:08.684321Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Archivo 'submission.csv' creado con 418 filas.\n   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1\n\nConteo predicciones: {0: 246, 1: 172}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# üèÜ Resultado del Submission\n\n- **Score Kaggle:** 0.75598  \n- **Notebook:** EPA_TITANIC_KNN_FE_V1.ipynb  \n- **Modelo:** KNN con Feature Engineering + GridSearch (k=13, p=1, uniform)  \n- **Notas:**  \n  - CV promedio: 0.8249  \n  - Buen desempe√±o interno, pero peor generalizaci√≥n en Kaggle (posible sobreajuste de KNN a las nuevas features).  \n  - Pr√≥ximo paso: probar un modelo basado en √°rboles (Random Forest, Gradient Boosting) con estas mismas features.  \n","metadata":{}}]}