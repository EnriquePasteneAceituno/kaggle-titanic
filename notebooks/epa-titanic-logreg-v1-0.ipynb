{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üö¢ EPA Titanic ‚Äî Logistic Regression V1\nModelo de **Regresi√≥n Log√≠stica** con Feature Engineering y Preprocesamiento.  \nEl objetivo es comparar contra los experimentos previos con KNN.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:41:58.172296Z","iopub.execute_input":"2025-08-29T02:41:58.172674Z","iopub.status.idle":"2025-08-29T02:42:00.668525Z","shell.execute_reply.started":"2025-08-29T02:41:58.172647Z","shell.execute_reply":"2025-08-29T02:42:00.667571Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# üì• Celda 2 ‚Äî Carga de datos\nLeemos `train.csv` y `test.csv` desde `/kaggle/input/titanic/`.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\nprint(\"Shape train:\", train_df.shape)\nprint(\"Shape test :\", test_df.shape)\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:42:43.438120Z","iopub.execute_input":"2025-08-29T02:42:43.438554Z","iopub.status.idle":"2025-08-29T02:42:43.501176Z","shell.execute_reply.started":"2025-08-29T02:42:43.438528Z","shell.execute_reply":"2025-08-29T02:42:43.499974Z"}},"outputs":[{"name":"stdout","text":"Shape train: (891, 12)\nShape test : (418, 11)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# üîé Celda 3 ‚Äî EDA breve (faltantes y balance de Survived)\nRevisamos columnas, valores faltantes (conteo y porcentaje) y el balance de la variable objetivo `Survived`.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np  # importamos numpy para operaciones num√©ricas simples\n\n# Mostramos la lista completa de columnas disponibles en el dataset de entrenamiento\nprint(\"Columnas en train:\", train_df.columns.tolist())  # imprime los nombres de las columnas de train_df\n\n# ---- Faltantes en TRAIN ----\nna_train = train_df.isna().sum()  # cuenta cu√°ntos valores NaN hay por columna en train\nna_train_pct = (na_train / len(train_df)).round(3)  # calcula el porcentaje de NaN por columna (redondea a 3 decimales)\nfaltantes_train = pd.DataFrame({\"nulos\": na_train, \"porcentaje\": na_train_pct})  # arma una tabla con conteo y porcentaje\nprint(\"\\nFaltantes en train (conteo y %):\")  # t√≠tulo de secci√≥n para legibilidad\nprint(faltantes_train.sort_values(\"nulos\", ascending=False))  # muestra primero las columnas con m√°s faltantes\n\n# ---- Faltantes en TEST ----\nna_test = test_df.isna().sum()  # cuenta NaN por columna en test\nna_test_pct = (na_test / len(test_df)).round(3)  # porcentaje de NaN por columna en test\nfaltantes_test = pd.DataFrame({\"nulos\": na_test, \"porcentaje\": na_test_pct})  # tabla similar para test\nprint(\"\\nFaltantes en test (conteo y %):\")  # t√≠tulo de secci√≥n\nprint(faltantes_test.sort_values(\"nulos\", ascending=False))  # ordena de mayor a menor cantidad de nulos\n\n# ---- Distribuci√≥n de la variable objetivo ----\ny_counts = train_df[\"Survived\"].value_counts().sort_index()  # cuenta cu√°ntos 0 y 1 hay (ordenado por valor)\ny_ratio = train_df[\"Survived\"].value_counts(normalize=True).sort_index().round(4)  # proporciones de 0 y 1 (redondeadas)\n\nprint(\"\\nDistribuci√≥n de Survived (conteo):\")  # t√≠tulo de secci√≥n\nprint(y_counts)  # imprime conteos de 0 y 1\n\nprint(\"\\nDistribuci√≥n de Survived (proporci√≥n):\")  # t√≠tulo de secci√≥n\nprint(y_ratio)  # imprime proporciones de 0 y 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:48:55.853275Z","iopub.execute_input":"2025-08-29T02:48:55.854206Z","iopub.status.idle":"2025-08-29T02:48:55.897624Z","shell.execute_reply.started":"2025-08-29T02:48:55.854168Z","shell.execute_reply":"2025-08-29T02:48:55.896320Z"}},"outputs":[{"name":"stdout","text":"Columnas en train: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nFaltantes en train (conteo y %):\n             nulos  porcentaje\nCabin          687       0.771\nAge            177       0.199\nEmbarked         2       0.002\nPassengerId      0       0.000\nSurvived         0       0.000\nPclass           0       0.000\nName             0       0.000\nSex              0       0.000\nSibSp            0       0.000\nParch            0       0.000\nTicket           0       0.000\nFare             0       0.000\n\nFaltantes en test (conteo y %):\n             nulos  porcentaje\nCabin          327       0.782\nAge             86       0.206\nFare             1       0.002\nPassengerId      0       0.000\nPclass           0       0.000\nName             0       0.000\nSex              0       0.000\nSibSp            0       0.000\nParch            0       0.000\nTicket           0       0.000\nEmbarked         0       0.000\n\nDistribuci√≥n de Survived (conteo):\nSurvived\n0    549\n1    342\nName: count, dtype: int64\n\nDistribuci√≥n de Survived (proporci√≥n):\nSurvived\n0    0.6162\n1    0.3838\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# üß± Celda 4 ‚Äî Definici√≥n de variables base y objetivo\nSeparamos las columnas que usaremos como **features base** (`X`, `X_test`) y el **target** (`y`).  \nAdem√°s guardamos `PassengerId` del test para construir luego el archivo de submission.\n","metadata":{}},{"cell_type":"code","source":"# --- Definici√≥n de columnas base ---\n# Num√©ricas originales\nbase_num_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n\n# Categ√≥ricas originales\nbase_cat_features = [\"Sex\", \"Embarked\"]\n\n# --- Construcci√≥n de X (features de entrenamiento) ---\nX = train_df[base_num_features + base_cat_features].copy()  # seleccionamos columnas base de train\n\n# --- Target ---\ny = train_df[\"Survived\"].astype(int)  # convertimos Survived a entero (0/1)\n\n# --- Construcci√≥n de X_test (features de predicci√≥n) ---\nX_test = test_df[base_num_features + base_cat_features].copy()  # seleccionamos columnas base de test\n\n# --- Guardamos PassengerId para el submission ---\ntest_passenger_id = test_df[\"PassengerId\"].copy()  # IDs del set de test\n\n# Vista previa de las primeras filas de X\nX.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:08.608284Z","iopub.execute_input":"2025-08-29T02:52:08.609055Z","iopub.status.idle":"2025-08-29T02:52:08.632382Z","shell.execute_reply.started":"2025-08-29T02:52:08.609020Z","shell.execute_reply":"2025-08-29T02:52:08.631166Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    Age  SibSp  Parch     Fare  Pclass     Sex Embarked\n0  22.0      1      0   7.2500       3    male        S\n1  38.0      1      0  71.2833       1  female        C\n2  26.0      0      0   7.9250       3  female        S\n3  35.0      1      0  53.1000       1  female        S\n4  35.0      0      0   8.0500       3    male        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>female</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>3</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# üß™ Celda 5 ‚Äî Ingenier√≠a de atributos\nCreamos nuevas variables a partir de las columnas originales:  \n\n- `FamilySize = SibSp + Parch + 1`  \n- `IsAlone = 1 si FamilySize == 1, else 0`  \n- `Title` (extra√≠do de la columna `Name`)  \n- `CabinKnown = 1 si Cabin no es NaN, else 0`  \n- `FarePerPerson = Fare / FamilySize`  \n- `TicketGroupSize = cantidad de pasajeros que comparten el mismo Ticket`  \n\nUsamos un `FunctionTransformer` para integrar estas transformaciones dentro del `Pipeline`.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer\n\n# Definimos la funci√≥n que a√±ade nuevas features al DataFrame\ndef add_features(df):\n    df = df.copy()  # trabajamos sobre una copia para no alterar el original\n\n    # --- FamilySize e IsAlone ---\n    df[\"FamilySize\"] = df[\"SibSp\"].fillna(0) + df[\"Parch\"].fillna(0) + 1\n    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n\n    # --- Title (extra√≠do de Name) ---\n    if \"Name\" in df.columns:\n        # extrae el t√≠tulo que est√° entre la coma y el punto\n        titles = df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\")[0]\n        # unifica variantes\n        titles = titles.replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n        # agrupa t√≠tulos raros en \"Other\"\n        titles = titles.where(titles.isin([\"Mr\",\"Mrs\",\"Miss\",\"Master\"]), \"Other\")\n        df[\"Title\"] = titles.fillna(\"Other\")\n    else:\n        df[\"Title\"] = \"Other\"\n\n    # --- CabinKnown (1 si Cabin no es NaN) ---\n    if \"Cabin\" in df.columns:\n        df[\"CabinKnown\"] = (~df[\"Cabin\"].isna()).astype(int)\n    else:\n        df[\"CabinKnown\"] = 0\n\n    # --- FarePerPerson ---\n    df[\"FarePerPerson\"] = df[\"Fare\"].fillna(df[\"Fare\"].median()) / df[\"FamilySize\"].replace(0, 1)\n\n    # --- TicketGroupSize ---\n    if \"Ticket\" in df.columns:\n        counts = df[\"Ticket\"].map(df[\"Ticket\"].value_counts())\n        df[\"TicketGroupSize\"] = counts.fillna(1).astype(int)\n    else:\n        df[\"TicketGroupSize\"] = 1\n\n    return df\n\n# Creamos el transformador para integrarlo en el pipeline\nfeature_engineering = FunctionTransformer(add_features, validate=False)\n\n# --- A√±adimos columnas auxiliares (Name, Ticket, Cabin) a X y X_test, necesarias para la ingenier√≠a de features ---\nfor col in [\"Name\", \"Ticket\", \"Cabin\"]:\n    if col not in X.columns:\n        X[col] = train_df[col]\n    if col not in X_test.columns:\n        X_test[col] = test_df[col]\n\nprint(\"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:57:41.175206Z","iopub.execute_input":"2025-08-29T02:57:41.176521Z","iopub.status.idle":"2025-08-29T02:57:41.187868Z","shell.execute_reply.started":"2025-08-29T02:57:41.176472Z","shell.execute_reply":"2025-08-29T02:57:41.186614Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido).\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# üßΩ Celda 6 ‚Äî Preprocesamiento (imputaci√≥n, escalado y One-Hot)\nDefinimos un `ColumnTransformer` que:\n- Imputa num√©ricas con **mediana** y las **escala** (LogReg es sensible a magnitudes).\n- Imputa categ√≥ricas con **moda** y aplica **One-Hot** (incluye `Title` creado en FE).\n","metadata":{}},{"cell_type":"code","source":"# Importamos utilidades para construir el preprocesamiento por tipo de columna\nfrom sklearn.compose import ColumnTransformer            # aplicar transformadores por columnas\nfrom sklearn.pipeline import Pipeline                    # encadenar pasos (FE -> preprocesamiento -> modelo)\nfrom sklearn.impute import SimpleImputer                 # imputaci√≥n de valores faltantes\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder  # escalado y codificaci√≥n one-hot\n\n# Definimos las columnas que EXISTIR√ÅN DESPU√âS del paso de Feature Engineering (Celda 5)\n# (Ojo: columnas auxiliares como Name/Ticket/Cabin NO van aqu√≠; solo las features finales que alimentar√°n al modelo)\nnum_features = [\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\",     # num√©ricas originales\n    \"FamilySize\", \"IsAlone\", \"FarePerPerson\",      # num√©ricas creadas\n    \"TicketGroupSize\", \"CabinKnown\"                # num√©ricas/bool creadas\n]\n\ncat_features = [\n    \"Sex\", \"Embarked\", \"Title\"                     # categ√≥ricas (Title viene de FE)\n]\n\n# Pipeline para columnas num√©ricas: imputar con mediana + escalar (recomendado para LogReg)\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),   # rellena NaN con la mediana (robusta a outliers)\n    (\"scaler\", StandardScaler())                     # estandariza a media 0 y desviaci√≥n 1\n])\n\n# Pipeline para columnas categ√≥ricas: imputar con la moda + One-Hot encoder\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),              # rellena NaN con el valor m√°s frecuente\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # dummies densos; ignora categor√≠as nuevas\n])\n\n# Combinamos ambos pipelines por tipo de columna\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_features),   # aplica numeric_transformer a num_features\n        (\"cat\", categorical_transformer, cat_features) # aplica categorical_transformer a cat_features\n    ],\n    remainder=\"drop\"  # descarta columnas no especificadas (p. ej., Name/Ticket/Cabin auxiliares)\n)\n\n# Mensaje de control para verificar listas\nprint(\"‚úÖ Preprocesamiento definido.\")\nprint(\"Num features:\", num_features)\nprint(\"Cat features:\", cat_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:02:24.671319Z","iopub.execute_input":"2025-08-29T03:02:24.672200Z","iopub.status.idle":"2025-08-29T03:02:25.092951Z","shell.execute_reply.started":"2025-08-29T03:02:24.672157Z","shell.execute_reply":"2025-08-29T03:02:25.091896Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Preprocesamiento definido.\nNum features: ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass', 'FamilySize', 'IsAlone', 'FarePerPerson', 'TicketGroupSize', 'CabinKnown']\nCat features: ['Sex', 'Embarked', 'Title']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# ü§ñ Celda 7 ‚Äî Pipeline con Regresi√≥n Log√≠stica y validaci√≥n cruzada\nEncadenamos **Feature Engineering ‚Üí Preprocesamiento ‚Üí LogisticRegression** en un `Pipeline`\ny evaluamos con **validaci√≥n cruzada estratificada (5 folds)** usando *accuracy*.\n","metadata":{}},{"cell_type":"code","source":"# Importamos el modelo y utilidades de validaci√≥n\nfrom sklearn.linear_model import LogisticRegression                  # modelo de regresi√≥n log√≠stica\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score  # CV estratificada y evaluaci√≥n\nimport numpy as np                                                    # operaciones num√©ricas\n\n# Definimos la regresi√≥n log√≠stica con iteraciones suficientes para converger\nlogreg = LogisticRegression(\n    max_iter=1000,     # aumenta el l√≠mite de iteraciones para asegurar convergencia\n    solver=\"lbfgs\",    # solver robusto para problemas multiclase y datos densos\n    n_jobs=-1          # paraleliza internamente algunas operaciones (si est√° disponible)\n)\n\n# Construimos el pipeline completo\npipe_logreg = Pipeline(steps=[\n    (\"fe\", feature_engineering),  # a√±ade features ingenierizadas a X\n    (\"pre\", preprocessor),        # imputaci√≥n, escalado, one-hot\n    (\"logreg\", logreg)            # modelo de regresi√≥n log√≠stica\n])\n\n# Definimos esquema de validaci√≥n cruzada estratificada (mantiene proporci√≥n 0/1 en cada fold)\ncv = StratifiedKFold(\n    n_splits=5,       # 5 folds\n    shuffle=True,     # barajar antes de dividir\n    random_state=42   # reproducibilidad\n)\n\n# Ejecutamos cross-validation con accuracy (m√©trica de la competici√≥n)\ncv_scores = cross_val_score(\n    estimator=pipe_logreg,  # el pipeline completo\n    X=X,                    # features base (la FE se aplica dentro del pipeline)\n    y=y,                    # target\n    cv=cv,                  # esquema de validaci√≥n\n    scoring=\"accuracy\",     # m√©trica\n    n_jobs=-1               # usar todos los cores disponibles\n)\n\n# Mostramos resultados por fold y resumen estad√≠stico\nprint(\"Accuracy por fold:\", np.round(cv_scores, 4))                  # accuracies individuales\nprint(\"Accuracy promedio (CV):\", cv_scores.mean().round(4),          # promedio\n      \"| Desv. std:\", cv_scores.std().round(4))                      # dispersi√≥n entre folds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:09:14.168534Z","iopub.execute_input":"2025-08-29T03:09:14.169002Z","iopub.status.idle":"2025-08-29T03:09:16.573382Z","shell.execute_reply.started":"2025-08-29T03:09:14.168971Z","shell.execute_reply":"2025-08-29T03:09:16.572478Z"}},"outputs":[{"name":"stdout","text":"Accuracy por fold: [0.8324 0.8146 0.8146 0.8371 0.8258]\nAccuracy promedio (CV): 0.8249 | Desv. std: 0.0091\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# üì§ Celda 8 ‚Äî Entrenamiento final y creaci√≥n de `submission.csv`\nEntrenamos el pipeline completo en **todo el set de entrenamiento** y generamos el archivo `submission.csv`\ncon las columnas `PassengerId` y `Survived` (formato requerido por Kaggle).\n","metadata":{}},{"cell_type":"code","source":"# 1) Ajustamos el pipeline completo en TODO el train\npipe_logreg.fit(X, y)                                # entrena FE + preprocesamiento + modelo\n\n# 2) Realizamos predicciones sobre el set de test\ntest_preds = pipe_logreg.predict(X_test)             # obtiene 0/1 por pasajero\ntest_preds = test_preds.astype(int)                  # aseguramos tipo entero\n\n# 3) Construimos el DataFrame de submission\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_passenger_id,               # IDs del test\n    \"Survived\": test_preds                          # predicciones binarias\n})\n\n# 4) Validaciones de formato (defensivas)\nassert submission.shape[0] == 418, \"El submission debe tener exactamente 418 filas.\"\nassert list(submission.columns) == [\"PassengerId\", \"Survived\"], \"Las columnas deben ser PassengerId y Survived.\"\n\n# 5) Guardamos el CSV para subir a Kaggle\nsubmission.to_csv(\"submission.csv\", index=False)\n\n# 6) Mensaje de confirmaci√≥n y breve vista previa\nprint(\"‚úÖ Archivo 'submission.csv' creado con\", submission.shape[0], \"filas.\")\nprint(submission.head())\nprint(\"\\nConteo predicciones:\", submission[\"Survived\"].value_counts().to_dict())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:14:11.391568Z","iopub.execute_input":"2025-08-29T03:14:11.392326Z","iopub.status.idle":"2025-08-29T03:14:11.508136Z","shell.execute_reply.started":"2025-08-29T03:14:11.392297Z","shell.execute_reply":"2025-08-29T03:14:11.506856Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Archivo 'submission.csv' creado con 418 filas.\n   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1\n\nConteo predicciones: {0: 251, 1: 167}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# üèÜ Celda 9 ‚Äî Registro del resultado\n\n- **Score Kaggle:** 0.77272  \n- **Notebook:** EPA_TITANIC_LOGREG_V1.ipynb  \n- **Modelo:** Regresi√≥n Log√≠stica con Feature Engineering  \n- **Notas:**  \n  - CV promedio (5 folds): 0.8249  \n  - Generaliz√≥ mejor que KNN (subi√≥ de 0.763 ‚Üí 0.772).  \n  - Buena estabilidad entre folds (std = 0.0091).  \n  - Primer modelo que mejora de forma consistente en leaderboard.  \n","metadata":{}}]}