{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üö¢ EPA Titanic ‚Äî LinearSVC V1 (M√°quina de Vectores de Soporte Lineal)\n\nEn este notebook probaremos **LinearSVC** (SVM lineal con el optimizador **liblinear/LinearSVC** de scikit-learn).\n\n## üîé ¬øQu√© es LinearSVC y en qu√© se diferencia?\n- **LinearSVC** aprende un **clasificador lineal de m√°ximo margen** usando la **p√©rdida hinge** (o squared hinge) con regularizaci√≥n **L2** (tambi√©n soporta L1 con `dual=False`).  \n- A diferencia de `SVC(kernel=\"linear\")`, que usa el solver de SMO y puede escalar peor con muchas features, **LinearSVC** est√° optimizado para problemas lineales y con muchas columnas (como tras **OneHotEncoder**).  \n- A diferencia de `SGDClassifier(loss=\"hinge\")`, que entrena por **descenso de gradiente estoc√°stico**, **LinearSVC** usa un optimizador determinista (coordinate descent/LibLinear), lo que suele dar **soluciones m√°s estables** (menos varianza) a costa de ser algo m√°s lento.\n\n## üéØ Objetivo\n1. Reutilizar **Feature Engineering** y **preprocesamiento** (imputaci√≥n, escalado, OneHot).  \n2. Entrenar un pipeline con **LinearSVC** y validar con **5-fold estratificado**.  \n3. Hacer **GridSearch** de hiperpar√°metros (`C`, `penalty`, `loss`, `dual`) para mejorar desempe√±o.  \n4. Generar `submission.csv` y registrar el resultado.\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:35:53.606861Z","iopub.execute_input":"2025-08-31T20:35:53.607187Z","iopub.status.idle":"2025-08-31T20:35:56.089875Z","shell.execute_reply.started":"2025-08-31T20:35:53.607152Z","shell.execute_reply":"2025-08-31T20:35:56.088709Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# üì• Celda 2 ‚Äî Carga de datos\nLeemos `train.csv` y `test.csv` desde `/kaggle/input/titanic/`, verificamos dimensiones y mostramos una vista previa.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # manejo de DataFrames (tablas)\n\n# Leemos los datos oficiales del entorno de competici√≥n\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")  # incluye Survived\ntest_df  = pd.read_csv(\"/kaggle/input/titanic/test.csv\")   # sin Survived\n\n# Mostramos formas esperadas (sanity check)\nprint(\"Shape train:\", train_df.shape)  # esperado ~ (891, 12)\nprint(\"Shape test :\", test_df.shape)   # esperado ~ (418, 11)\n\n# Vista r√°pida de columnas y tipos\ntrain_df.head()  # primeras 5 filas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:37:24.450058Z","iopub.execute_input":"2025-08-31T20:37:24.450372Z","iopub.status.idle":"2025-08-31T20:37:24.517302Z","shell.execute_reply.started":"2025-08-31T20:37:24.450347Z","shell.execute_reply":"2025-08-31T20:37:24.516695Z"}},"outputs":[{"name":"stdout","text":"Shape train: (891, 12)\nShape test : (418, 11)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# üîé Celda 3 ‚Äî Exploraci√≥n inicial (EDA breve)\nEn esta celda:  \n- Listamos las columnas del dataset de entrenamiento.  \n- Revisamos valores faltantes en `train.csv` y `test.csv` (conteo y porcentaje).  \n- Analizamos la distribuci√≥n de la variable objetivo `Survived` para entender el balance de clases.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np  # librer√≠a de utilidades num√©ricas\n\n# --- Listado de columnas ---\nprint(\"Columnas en train:\", train_df.columns.tolist())\n\n# --- Faltantes en TRAIN ---\nna_train = train_df.isna().sum()                          # cuenta valores nulos\nna_train_pct = (na_train / len(train_df)).round(3)        # porcentaje de nulos\nfaltantes_train = pd.DataFrame({\"nulos\": na_train, \"porcentaje\": na_train_pct})\nprint(\"\\nFaltantes en train (conteo y %):\")\nprint(faltantes_train.sort_values(\"nulos\", ascending=False))\n\n# --- Faltantes en TEST ---\nna_test = test_df.isna().sum()\nna_test_pct = (na_test / len(test_df)).round(3)\nfaltantes_test = pd.DataFrame({\"nulos\": na_test, \"porcentaje\": na_test_pct})\nprint(\"\\nFaltantes en test (conteo y %):\")\nprint(faltantes_test.sort_values(\"nulos\", ascending=False))\n\n# --- Distribuci√≥n de Survived ---\ny_counts = train_df[\"Survived\"].value_counts().sort_index()\ny_ratio = train_df[\"Survived\"].value_counts(normalize=True).round(4)\n\nprint(\"\\nDistribuci√≥n de Survived (conteo):\")\nprint(y_counts)\nprint(\"\\nDistribuci√≥n de Survived (proporci√≥n):\")\nprint(y_ratio)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:40:54.358990Z","iopub.execute_input":"2025-08-31T20:40:54.359367Z","iopub.status.idle":"2025-08-31T20:40:54.395783Z","shell.execute_reply.started":"2025-08-31T20:40:54.359340Z","shell.execute_reply":"2025-08-31T20:40:54.394727Z"}},"outputs":[{"name":"stdout","text":"Columnas en train: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nFaltantes en train (conteo y %):\n             nulos  porcentaje\nCabin          687       0.771\nAge            177       0.199\nEmbarked         2       0.002\nPassengerId      0       0.000\nSurvived         0       0.000\nPclass           0       0.000\nName             0       0.000\nSex              0       0.000\nSibSp            0       0.000\nParch            0       0.000\nTicket           0       0.000\nFare             0       0.000\n\nFaltantes en test (conteo y %):\n             nulos  porcentaje\nCabin          327       0.782\nAge             86       0.206\nFare             1       0.002\nPassengerId      0       0.000\nPclass           0       0.000\nName             0       0.000\nSex              0       0.000\nSibSp            0       0.000\nParch            0       0.000\nTicket           0       0.000\nEmbarked         0       0.000\n\nDistribuci√≥n de Survived (conteo):\nSurvived\n0    549\n1    342\nName: count, dtype: int64\n\nDistribuci√≥n de Survived (proporci√≥n):\nSurvived\n0    0.6162\n1    0.3838\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# üß± Celda 4 ‚Äî Definici√≥n de variables base y objetivo\nEn esta celda:  \n- Seleccionamos las columnas **num√©ricas** y **categ√≥ricas** originales como punto de partida.  \n- Construimos la matriz de features `X` (entrenamiento) y `X_test` (predicci√≥n).  \n- Definimos la variable objetivo `y` (`Survived`).  \n- Guardamos `PassengerId` del test para usarlo al crear el `submission.csv`.\n","metadata":{}},{"cell_type":"code","source":"# --- Definici√≥n de columnas base ---\n# Variables num√©ricas originales\nbase_num_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n\n# Variables categ√≥ricas originales\nbase_cat_features = [\"Sex\", \"Embarked\"]\n\n# --- Construcci√≥n de X (features de entrenamiento) ---\nX = train_df[base_num_features + base_cat_features].copy()\n\n# --- Variable objetivo ---\ny = train_df[\"Survived\"].astype(int)  # aseguramos tipo entero (0/1)\n\n# --- Construcci√≥n de X_test (features de predicci√≥n) ---\nX_test = test_df[base_num_features + base_cat_features].copy()\n\n# --- Guardamos PassengerId (para el submission) ---\ntest_passenger_id = test_df[\"PassengerId\"].copy()\n\n# Vista previa de X\nX.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:46:29.351422Z","iopub.execute_input":"2025-08-31T20:46:29.351931Z","iopub.status.idle":"2025-08-31T20:46:29.374258Z","shell.execute_reply.started":"2025-08-31T20:46:29.351900Z","shell.execute_reply":"2025-08-31T20:46:29.373087Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"    Age  SibSp  Parch     Fare  Pclass     Sex Embarked\n0  22.0      1      0   7.2500       3    male        S\n1  38.0      1      0  71.2833       1  female        C\n2  26.0      0      0   7.9250       3  female        S\n3  35.0      1      0  53.1000       1  female        S\n4  35.0      0      0   8.0500       3    male        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>female</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>3</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# üß™ Celda 5 ‚Äî Ingenier√≠a de atributos\nEn esta celda crearemos nuevas variables derivadas de las originales para enriquecer el modelo:\n\n- **FamilySize** = SibSp + Parch + 1  \n- **IsAlone** = 1 si FamilySize == 1, en caso contrario 0  \n- **Title** = extra√≠do de la columna Name (agrupando t√≠tulos raros en \"Other\")  \n- **CabinKnown** = 1 si Cabin no es NaN, 0 en caso contrario  \n- **FarePerPerson** = Fare dividido por FamilySize  \n- **TicketGroupSize** = n√∫mero de pasajeros que comparten el mismo Ticket  \n\nEstas transformaciones se implementar√°n en una funci√≥n y se integrar√°n en el pipeline con `FunctionTransformer`.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer  # para aplicar funciones personalizadas en un Pipeline\n\n# Definimos la funci√≥n de ingenier√≠a de atributos\ndef add_features(df):\n    df = df.copy()\n\n    # --- FamilySize e IsAlone ---\n    df[\"FamilySize\"] = df[\"SibSp\"].fillna(0) + df[\"Parch\"].fillna(0) + 1\n    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n\n    # --- Title (extra√≠do de Name) ---\n    if \"Name\" in df.columns:\n        titles = df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\")[0]\n        titles = titles.replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n        titles = titles.where(titles.isin([\"Mr\",\"Mrs\",\"Miss\",\"Master\"]), \"Other\")\n        df[\"Title\"] = titles.fillna(\"Other\")\n    else:\n        df[\"Title\"] = \"Other\"\n\n    # --- CabinKnown ---\n    if \"Cabin\" in df.columns:\n        df[\"CabinKnown\"] = (~df[\"Cabin\"].isna()).astype(int)\n    else:\n        df[\"CabinKnown\"] = 0\n\n    # --- FarePerPerson ---\n    df[\"FarePerPerson\"] = df[\"Fare\"].fillna(df[\"Fare\"].median()) / df[\"FamilySize\"].replace(0, 1)\n\n    # --- TicketGroupSize ---\n    if \"Ticket\" in df.columns:\n        counts = df[\"Ticket\"].map(df[\"Ticket\"].value_counts())\n        df[\"TicketGroupSize\"] = counts.fillna(1).astype(int)\n    else:\n        df[\"TicketGroupSize\"] = 1\n\n    return df\n\n# Creamos el transformador para usar dentro del pipeline\nfeature_engineering = FunctionTransformer(add_features, validate=False)\n\n# A√±adimos columnas auxiliares necesarias a X y X_test (Name, Ticket, Cabin)\nfor col in [\"Name\", \"Ticket\", \"Cabin\"]:\n    if col not in X.columns and col in train_df.columns:\n        X[col] = train_df[col]\n    if col not in X_test.columns and col in test_df.columns:\n        X_test[col] = test_df[col]\n\nprint(\"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido y columnas auxiliares a√±adidas).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:50:18.992592Z","iopub.execute_input":"2025-08-31T20:50:18.992980Z","iopub.status.idle":"2025-08-31T20:50:19.673037Z","shell.execute_reply.started":"2025-08-31T20:50:18.992951Z","shell.execute_reply":"2025-08-31T20:50:19.672015Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Ingenier√≠a de atributos lista (FunctionTransformer definido y columnas auxiliares a√±adidas).\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# üßΩ Celda 6 ‚Äî Preprocesamiento (imputaci√≥n, escalado y One-Hot)\nVamos a preparar un `ColumnTransformer` que:\n- Imputa **num√©ricas** con **mediana** y luego **escala** (SVM/LinearSVC es sensible a magnitudes).\n- Imputa **categ√≥ricas** con **moda** y aplica **One-Hot** (incluye `Title` creado en la Celda 5).\n\n> Nota: Solo listamos las **features finales** que entran al modelo.  \n> Las columnas auxiliares (`Name`, `Ticket`, `Cabin`) no se usan directamente, solo sirven para crear features.\n","metadata":{}},{"cell_type":"code","source":"# Importamos utilidades para construir el preprocesamiento por tipo de columna\nfrom sklearn.compose import ColumnTransformer            # aplicar distintos transformadores por columna\nfrom sklearn.pipeline import Pipeline                    # encadenar pasos (FE -> pre -> modelo)\nfrom sklearn.impute import SimpleImputer                 # imputaci√≥n de faltantes\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder  # escalado y one-hot\n\n# Definimos las columnas que EXISTIR√ÅN DESPU√âS del Feature Engineering (Celda 5)\nnum_features = [                                         # variables num√©ricas finales\n    \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\",           # num√©ricas originales\n    \"FamilySize\", \"IsAlone\", \"FarePerPerson\",            # creadas\n    \"TicketGroupSize\", \"CabinKnown\"                      # creadas (CabinKnown es binaria, la tratamos como num√©rica)\n]\ncat_features = [                                         # variables categ√≥ricas finales\n    \"Sex\", \"Embarked\", \"Title\"                           # Title proviene de la Celda 5\n]\n\n# Pipeline para num√©ricas: imputar con mediana y escalar (muy importante para LinearSVC)\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),       # rellena NaN en num√©ricas con la mediana\n    (\"scaler\", StandardScaler())                         # estandariza (media 0, desv√≠o 1)\n])\n\n# Pipeline para categ√≥ricas: imputar con moda y codificar con One-Hot\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),             # rellena NaN en categ√≥ricas con la moda\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\",                 # crea dummies; ignora categor√≠as no vistas\n                             sparse_output=False))                    # salida densa (dataset es peque√±o)\n])\n\n# Componemos el ColumnTransformer, aplicando cada pipeline a sus columnas\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_features),      # aplica pipeline num√©rico a num_features\n        (\"cat\", categorical_transformer, cat_features)   # aplica pipeline categ√≥rico a cat_features\n    ],\n    remainder=\"drop\"                                     # descarta columnas no listadas (Name/Ticket/Cabin)\n)\n\n# Mensajes de verificaci√≥n\nprint(\"‚úÖ Preprocesamiento definido para LinearSVC.\")\nprint(\"Num features:\", num_features)\nprint(\"Cat features:\", cat_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:05:25.296818Z","iopub.execute_input":"2025-08-31T21:05:25.299058Z","iopub.status.idle":"2025-08-31T21:05:25.773732Z","shell.execute_reply.started":"2025-08-31T21:05:25.299010Z","shell.execute_reply":"2025-08-31T21:05:25.772757Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Preprocesamiento definido para LinearSVC.\nNum features: ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass', 'FamilySize', 'IsAlone', 'FarePerPerson', 'TicketGroupSize', 'CabinKnown']\nCat features: ['Sex', 'Embarked', 'Title']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# ü§ñ Celda 7 ‚Äî Pipeline (FE ‚Üí Preprocesamiento ‚Üí LinearSVC) + Validaci√≥n Cruzada\nEncadenamos la **Ingenier√≠a de Features**, el **preprocesamiento** y el modelo **LinearSVC** en un `Pipeline`.\nEvaluamos con **5-fold Stratified CV** usando *accuracy* (m√©trica oficial de la competici√≥n).\n\n> Notas de configuraci√≥n:\n> - `LinearSVC` usa la p√©rdida **squared_hinge** por defecto (SVM lineal).\n> - Con **m√°s muestras que features** (nuestro caso tras OneHot), suele ser m√°s eficiente `dual=False`.\n> - El modelo es sensible a la escala ‚Üí ya estandarizamos en el preprocesamiento.\n","metadata":{}},{"cell_type":"code","source":"# Importamos el modelo y utilidades de evaluaci√≥n\nfrom sklearn.svm import LinearSVC                          # SVM lineal (optimizaci√≥n determinista)\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score  # CV estratificada y evaluaci√≥n\nfrom sklearn.pipeline import Pipeline                      # para encadenar pasos\nimport numpy as np                                         # utilidades num√©ricas\n\n# Definimos un LinearSVC \"baseline\" robusto\nlinsvc = LinearSVC(\n    penalty=\"l2\",        # regularizaci√≥n L2 (est√°ndar y estable)\n    loss=\"squared_hinge\",# p√©rdida por defecto en LinearSVC\n    C=1.0,               # fuerza de regularizaci√≥n (m√°s alto = menos regularizaci√≥n)\n    dual=False,          # con n_samples > n_features suele ser m√°s eficiente desactivar dual\n    tol=1e-4,            # tolerancia de parada\n    max_iter=5000        # iteraciones m√°ximas (evita warnings de convergencia)\n    # class_weight=\"balanced\"  # <- opcional para compensar leve desbalance 0/1\n)\n\n# Construimos el pipeline completo: FE -> Preprocesamiento -> Modelo\npipe_linsvc = Pipeline(steps=[\n    (\"fe\", feature_engineering),  # Celda 5: genera FamilySize, Title, etc.\n    (\"pre\", preprocessor),        # Celda 6: imputaci√≥n + escalado + OneHot\n    (\"linsvc\", linsvc)            # clasificador LinearSVC\n])\n\n# Definimos el esquema de validaci√≥n cruzada estratificada\ncv = StratifiedKFold(\n    n_splits=5,       # 5 folds\n    shuffle=True,     # barajamos antes de partir\n    random_state=42   # reproducibilidad en el split\n)\n\n# Ejecutamos cross-validation con accuracy\ncv_scores = cross_val_score(\n    estimator=pipe_linsvc,  # pipeline completo\n    X=X,                    # features base (FE se aplica dentro del pipeline)\n    y=y,                    # objetivo (Survived)\n    cv=cv,                  # esquema de validaci√≥n\n    scoring=\"accuracy\",     # m√©trica oficial de la competencia\n    n_jobs=-1               # usa todos los n√∫cleos disponibles\n)\n\n# Mostramos resultados por fold y resumen\nprint(\"Accuracy por fold:\", np.round(cv_scores, 4))                 # accuracies individuales\nprint(\"Accuracy promedio (CV):\", cv_scores.mean().round(4),         # promedio de CV\n      \"| Desv. std:\", cv_scores.std().round(4))                     # dispersi√≥n entre folds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:11:56.881545Z","iopub.execute_input":"2025-08-31T21:11:56.882009Z","iopub.status.idle":"2025-08-31T21:11:59.310847Z","shell.execute_reply.started":"2025-08-31T21:11:56.881975Z","shell.execute_reply":"2025-08-31T21:11:59.309714Z"}},"outputs":[{"name":"stdout","text":"Accuracy por fold: [0.8268 0.8146 0.8258 0.8371 0.8427]\nAccuracy promedio (CV): 0.8294 | Desv. std: 0.0097\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# üì§ Celda 8 ‚Äî Entrenamiento final y creaci√≥n de `submission.csv`\nEntrenamos el **pipeline completo con LinearSVC** en **todo `train`** y generamos el archivo\n`submission.csv` (formato Kaggle: `PassengerId`, `Survived`, 418 filas).\n","metadata":{}},{"cell_type":"code","source":"# 1) Entrenamos el pipeline completo (FE ‚Üí Preprocesamiento ‚Üí LinearSVC) con TODO el train\npipe_linsvc.fit(X, y)  # ajusta usando todas las filas de entrenamiento\n\n# 2) Obtenemos predicciones binarias (0/1) sobre el set de test\ntest_preds = pipe_linsvc.predict(X_test)  # LinearSVC no tiene predict_proba; trabajamos con clases\ntest_preds = test_preds.astype(int)       # nos aseguramos de que la salida sea entera\n\n# 3) Construimos el DataFrame en el formato requerido por Kaggle\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_passenger_id,  # IDs originales del conjunto de test\n    \"Survived\": test_preds             # predicciones del modelo\n})\n\n# 4) Chequeos defensivos de formato (muy √∫til para evitar errores de subida)\nassert submission.shape[0] == 418, \"El submission debe tener exactamente 418 filas.\"\nassert list(submission.columns) == [\"PassengerId\", \"Survived\"], \"Columnas deben ser PassengerId y Survived.\"\n\n# 5) Guardamos el CSV en disco (Kaggle lo detecta para la pesta√±a 'Submit Predictions')\nsubmission.to_csv(\"submission.csv\", index=False)  # guarda sin √≠ndice\n\n# 6) Mensajes de confirmaci√≥n y vista previa\nprint(\"‚úÖ Archivo 'submission.csv' creado con\", submission.shape[0], \"filas.\")\nprint(submission.head())  # primeras 5 filas para inspecci√≥n r√°pida\nprint(\"\\nConteo predicciones:\", submission[\"Survived\"].value_counts().to_dict())  # distribuci√≥n 0/1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T21:18:07.472002Z","iopub.execute_input":"2025-08-31T21:18:07.472389Z","iopub.status.idle":"2025-08-31T21:18:07.573057Z","shell.execute_reply.started":"2025-08-31T21:18:07.472361Z","shell.execute_reply":"2025-08-31T21:18:07.571912Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Archivo 'submission.csv' creado con 418 filas.\n   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1\n\nConteo predicciones: {0: 253, 1: 165}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# üèÜ Celda 9 ‚Äî Registro del resultado\n\n- **Score Kaggle:** 0.77272  \n- **Notebook:** EPA_TITANIC_LINSVC_V1.ipynb  \n- **Modelo:** LinearSVC (m√°quina de vectores de soporte lineal)  \n- **Hiperpar√°metros:**  \n  - penalty = \"l2\"  \n  - loss = \"squared_hinge\"  \n  - C = 1.0  \n  - dual = False  \n  - max_iter = 5000  \n- **Resultados:**  \n  - CV promedio: 0.8294 (std 0.0097)  \n  - Kaggle score: 0.77272 (empatado con LogReg V1, ligeramente peor que SGD V1)  \n- **Notas:**  \n  - El modelo fue muy estable en CV, pero en Kaggle no super√≥ a SGD.  \n  - Pr√≥ximos pasos: probar ensambles de √°rboles (Random Forest, Gradient Boosting) para buscar un salto mayor.  \n","metadata":{}}]}