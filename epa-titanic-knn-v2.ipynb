{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üö¢ Kaggle Competition: Titanic - Machine Learning from Disaster\n**Notebook: EPA Titanic KNN v1.1**\n\n## üéØ Objetivo\nPredecir qu√© pasajeros sobrevivieron al hundimiento del Titanic usando un modelo de **K-Nearest Neighbors (KNN)**.  \nEste notebook busca ser un ejercicio de aprendizaje, mostrando paso a paso c√≥mo preparar los datos, entrenar un modelo, ajustar hiperpar√°metros y generar un archivo `submission.csv` v√°lido para Kaggle.\n\n## üìÇ Dataset\nLos archivos provienen de la competici√≥n oficial en Kaggle:\n- **train.csv** ‚Üí 891 pasajeros, con la variable objetivo `Survived`.\n- **test.csv** ‚Üí 418 pasajeros, sin `Survived` (a predecir).\n- **gender_submission.csv** ‚Üí ejemplo de submission v√°lido.\n\n## üß© Flujo del Notebook\n1. ‚öôÔ∏è Configuraci√≥n inicial de Kaggle  \n2. üì• Carga de datos (train y test)  \n3. üîé An√°lisis exploratorio inicial (faltantes y balance de clases)  \n4. üß± Selecci√≥n de variables (features y objetivo)  \n5. üßΩ Definici√≥n del preprocesamiento (imputaci√≥n, escalado, one-hot)  \n6. ü§ñ Pipeline con KNN y validaci√≥n cruzada  \n7. üîé B√∫squeda de hiperpar√°metros (Grid Search para KNN)  \n8. üì§ Entrenamiento final y creaci√≥n del archivo `submission.csv`\n\n---\n\n‚ú® **Nota:** Todo el notebook est√° comentado en espa√±ol, para facilitar la comprensi√≥n del flujo de trabajo en Kaggle.","metadata":{}},{"cell_type":"markdown","source":"# ‚öôÔ∏è Celda 1 ‚Äî Configuraci√≥n inicial de Kaggle\nEste bloque viene por defecto en el notebook. Lista los archivos disponibles en `/kaggle/input/titanic/`.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:03:03.860515Z","iopub.execute_input":"2025-08-28T04:03:03.860963Z","iopub.status.idle":"2025-08-28T04:03:03.869896Z","shell.execute_reply.started":"2025-08-28T04:03:03.860939Z","shell.execute_reply":"2025-08-28T04:03:03.868274Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# üì• Celda 2 ‚Äî Carga de datos (train y test)\nLeemos los archivos `train.csv` y `test.csv` y verificamos sus dimensiones.","metadata":{}},{"cell_type":"code","source":"# Importamos pandas para leer CSV y manipular DataFrames\nimport pandas as pd\n\n# Definimos las rutas de los archivos provistos por la competencia\ntrain_path = \"/kaggle/input/titanic/train.csv\"   # ruta del set de entrenamiento\ntest_path  = \"/kaggle/input/titanic/test.csv\"    # ruta del set de test (sin Survived)\n\n# Leemos los CSV a DataFrames de pandas\ntrain_df = pd.read_csv(train_path)  # carga train.csv\ntest_df  = pd.read_csv(test_path)   # carga test.csv\n\n# Inspeccionamos las dimensiones de cada DataFrame\nprint(\"Shape train:\", train_df.shape)  # imprime filas/columnas de train\nprint(\"Shape test :\", test_df.shape)   # imprime filas/columnas de test\n\n# Mostramos las primeras filas del set de entrenamiento para conocer la estructura\ntrain_df.head()  # vista r√°pida de columnas y ejemplos\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:00:35.930986Z","iopub.execute_input":"2025-08-28T04:00:35.931398Z","iopub.status.idle":"2025-08-28T04:00:35.972590Z","shell.execute_reply.started":"2025-08-28T04:00:35.931370Z","shell.execute_reply":"2025-08-28T04:00:35.970622Z"}},"outputs":[{"name":"stdout","text":"Shape train: (891, 12)\nShape test : (418, 11)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# üîé Celda 3 ‚Äî An√°lisis exploratorio inicial\nRevisamos columnas disponibles, valores faltantes en cada dataset y el balance de la variable objetivo `Survived`.","metadata":{}},{"cell_type":"code","source":"# Mostramos las columnas disponibles en el dataset de entrenamiento\nprint(\"Columnas en train:\", train_df.columns.tolist())\n\n# Revisamos cu√°ntos valores faltantes (NaN) hay por columna en train\nprint(\"\\nFaltantes en train:\")\nprint(train_df.isna().sum())\n\n# Revisamos cu√°ntos valores faltantes (NaN) hay por columna en test\nprint(\"\\nFaltantes en test:\")\nprint(test_df.isna().sum())\n\n# Verificamos la distribuci√≥n de la variable objetivo Survived (0 = no, 1 = s√≠)\nprint(\"\\nDistribuci√≥n de Survived en train:\")\nprint(train_df[\"Survived\"].value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:01:06.140649Z","iopub.execute_input":"2025-08-28T04:01:06.141499Z","iopub.status.idle":"2025-08-28T04:01:06.154472Z","shell.execute_reply.started":"2025-08-28T04:01:06.141463Z","shell.execute_reply":"2025-08-28T04:01:06.153173Z"}},"outputs":[{"name":"stdout","text":"Columnas en train: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nFaltantes en train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nFaltantes en test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\nDistribuci√≥n de Survived en train:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# üß± Celda 4 ‚Äî Selecci√≥n de variables (features y objetivo)\nDefinimos qu√© columnas usaremos como variables predictoras (`X`) y cu√°l ser√° la variable objetivo (`y`).","metadata":{}},{"cell_type":"code","source":"# Definimos las columnas num√©ricas que usaremos como caracter√≠sticas (features)\nnum_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]  \n# -> Edad, n¬∫ de hermanos/esposos, n¬∫ de padres/hijos, tarifa y clase social\n\n# Definimos las columnas categ√≥ricas que usaremos como caracter√≠sticas\ncat_features = [\"Sex\", \"Embarked\"]  \n# -> Sexo y puerto de embarque\n\n# Construimos la matriz de caracter√≠sticas X a partir de train\nX = train_df[num_features + cat_features]\n\n# Construimos el vector objetivo y (sobrevivi√≥ o no)\ny = train_df[\"Survived\"].astype(int)\n\n# Guardamos los PassengerId de test para poder armar el submission al final\ntest_passenger_id = test_df[\"PassengerId\"].copy()\n\n# Construimos la matriz de caracter√≠sticas X_test con las mismas columnas que X\nX_test = test_df[num_features + cat_features]\n\n# Revisamos las primeras filas de X para validar que tenemos las features correctas\nX.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:01:34.887604Z","iopub.execute_input":"2025-08-28T04:01:34.888025Z","iopub.status.idle":"2025-08-28T04:01:34.906521Z","shell.execute_reply.started":"2025-08-28T04:01:34.887986Z","shell.execute_reply":"2025-08-28T04:01:34.905316Z"},"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"    Age  SibSp  Parch     Fare  Pclass     Sex Embarked\n0  22.0      1      0   7.2500       3    male        S\n1  38.0      1      0  71.2833       1  female        C\n2  26.0      0      0   7.9250       3  female        S\n3  35.0      1      0  53.1000       1  female        S\n4  35.0      0      0   8.0500       3    male        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>female</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>3</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>female</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>3</td>\n      <td>male</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# üßΩ Celda 5 ‚Äî Definici√≥n del preprocesamiento\nCreamos pipelines de preprocesamiento para variables num√©ricas (imputaci√≥n + escalado) y categ√≥ricas (imputaci√≥n + one-hot).","metadata":{}},{"cell_type":"code","source":"# Importamos los m√≥dulos necesarios para preprocesar y construir pipelines\nfrom sklearn.compose import ColumnTransformer                 # permite aplicar transformaciones por tipo de columna\nfrom sklearn.pipeline import Pipeline                         # encadena pasos (preprocesamiento + modelo)\nfrom sklearn.impute import SimpleImputer                      # para imputar (rellenar) valores faltantes\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler  # codificaci√≥n categ√≥rica y escalado num√©rico\n\n# Definimos un pipeline para columnas num√©ricas\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),  # rellena NaN con la mediana (robusta a outliers)\n    (\"scaler\", StandardScaler())                    # estandariza a media 0 y desv√≠o 1 (cr√≠tico para KNN)\n])\n\n# Definimos un pipeline para columnas categ√≥ricas\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),          # rellena NaN con la moda (valor m√°s frecuente)\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))  # convierte categor√≠as a variables dummies\n])\n\n# Combinamos ambos pipelines por tipo de columna usando ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_features),  # aplica el pipeline num√©rico a las columnas num√©ricas\n        (\"cat\", categorical_transformer, cat_features)  # aplica el pipeline categ√≥rico a las columnas categ√≥ricas\n    ],\n    remainder=\"drop\"  # descarta cualquier columna no especificada (por seguridad)\n)\n\n# vista r√°pida: mostramos qu√© columnas estamos declarando por tipo\nprint(\"Columnas num√©ricas:\", num_features)    # deber√≠a listar ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\nprint(\"Columnas categ√≥ricas:\", cat_features)  # deber√≠a listar ['Sex', 'Embarked']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:59:04.136473Z","iopub.execute_input":"2025-08-28T03:59:04.137092Z","iopub.status.idle":"2025-08-28T03:59:04.146546Z","shell.execute_reply.started":"2025-08-28T03:59:04.137058Z","shell.execute_reply":"2025-08-28T03:59:04.145311Z"}},"outputs":[{"name":"stdout","text":"Columnas num√©ricas: ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\nColumnas categ√≥ricas: ['Sex', 'Embarked']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# ü©π Celda 5.1 ‚Äî Parche OneHotEncoder (evitar FutureWarning)\nRe-definimos el `OneHotEncoder` usando el nuevo par√°metro `sparse_output=False` para eliminar las advertencias de futuro de scikit-learn.","metadata":{}},{"cell_type":"code","source":"# ü©π Parche: re-definimos el transformador categ√≥rico usando el par√°metro moderno 'sparse_output'\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),                 # moda para NaN\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # dummies densos sin warning\n])\n\n# Re-construimos el preprocessor con el nuevo categorical_transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_features),   # num√©ricas: mediana + escalado\n        (\"cat\", categorical_transformer, cat_features) # categ√≥ricas: moda + one-hot\n    ],\n    remainder=\"drop\"\n)\n\nprint(\"‚úÖ Parche aplicado: OneHotEncoder usa 'sparse_output=False'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:13:26.013418Z","iopub.execute_input":"2025-08-28T04:13:26.013880Z","iopub.status.idle":"2025-08-28T04:13:26.023105Z","shell.execute_reply.started":"2025-08-28T04:13:26.013853Z","shell.execute_reply":"2025-08-28T04:13:26.021802Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parche aplicado: OneHotEncoder usa 'sparse_output=False'\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# ü§ñ Celda 6 ‚Äî Pipeline con KNN y validaci√≥n cruzada\nArmamos un pipeline que incluye el preprocesamiento y un modelo KNN. Evaluamos su desempe√±o con validaci√≥n cruzada estratificada.i","metadata":{}},{"cell_type":"code","source":"# Importamos el clasificador KNN de scikit-learn\nfrom sklearn.neighbors import KNeighborsClassifier\n# Importamos validaci√≥n cruzada estratificada (mantiene proporci√≥n de clases en cada fold)\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n# Importamos numpy para operaciones num√©ricas y redondeos\nimport numpy as np\n\n# Definimos un modelo base de KNN con hiperpar√°metros razonables de partida\nbase_knn = KNeighborsClassifier(\n    n_neighbors=7,   # n√∫mero de vecinos (k); valor inicial que suele rendir bien en Titanic\n    weights=\"uniform\",  # todos los vecinos pesan igual (alternativa: \"distance\")\n    p=2                # m√©trica Minkowski con p=2 equivale a distancia Eucl√≠dea\n)\n\n# Construimos el pipeline completo: primero preprocesa, luego entrena el KNN\npipe_knn = Pipeline(steps=[\n    (\"preprocess\", preprocessor),  # aplica imputaci√≥n, escalado y one-hot definidos en la Celda 5\n    (\"knn\", base_knn)              # clasificador KNN como √∫ltimo paso\n])\n\n# Definimos la estrategia de validaci√≥n cruzada estratificada con 5 pliegues\ncv = StratifiedKFold(\n    n_splits=5,     # n√∫mero de folds\n    shuffle=True,   # baraja los datos antes de dividir\n    random_state=42 # semilla para reproducibilidad\n)\n\n# Ejecutamos la validaci√≥n cruzada usando accuracy como m√©trica\ncv_scores = cross_val_score(\n    estimator=pipe_knn,  # el pipeline completo (prepro + modelo)\n    X=X,                 # matriz de caracter√≠sticas de entrenamiento (de la Celda 4)\n    y=y,                 # vector objetivo (de la Celda 4)\n    cv=cv,               # esquema de validaci√≥n cruzada\n    scoring=\"accuracy\",  # m√©trica de evaluaci√≥n\n    n_jobs=-1            # usa todos los n√∫cleos disponibles para acelerar\n)\n\n# Imprimimos los resultados de accuracy por fold redondeados a 4 decimales\nprint(\"Accuracy por fold:\", np.round(cv_scores, 4))\n# Imprimimos el promedio y la desviaci√≥n est√°ndar de accuracy en los 5 folds\nprint(\"Accuracy promedio (CV):\", cv_scores.mean().round(4), \"| Desv. std:\", cv_scores.std().round(4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:13:46.230919Z","iopub.execute_input":"2025-08-28T04:13:46.231361Z","iopub.status.idle":"2025-08-28T04:13:46.355551Z","shell.execute_reply.started":"2025-08-28T04:13:46.231332Z","shell.execute_reply":"2025-08-28T04:13:46.354289Z"}},"outputs":[{"name":"stdout","text":"Accuracy por fold: [0.8156 0.809  0.7978 0.8146 0.8202]\nAccuracy promedio (CV): 0.8114 | Desv. std: 0.0077\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# üîé Celda 7 ‚Äî B√∫squeda de hiperpar√°metros (Grid Search para KNN)\nUsamos `GridSearchCV` para encontrar la mejor combinaci√≥n de `n_neighbors`, `weights` y `p` (distancia), manteniendo el preprocesamiento dentro del pipeline.","metadata":{}},{"cell_type":"code","source":"# Importamos las utilidades necesarias para la b√∫squeda en grilla\nfrom sklearn.model_selection import GridSearchCV                 # b√∫squeda exhaustiva de hiperpar√°metros\nfrom sklearn.neighbors import KNeighborsClassifier               # clasificador KNN\nfrom sklearn.model_selection import StratifiedKFold              # CV estratificada (para reproducibilidad)\nimport pandas as pd                                              # para tabular resultados\n\n# Reconstruimos el pipeline (por claridad) con el preprocesador ya definido y un KNN \"vac√≠o\" (lo definir√° la grilla)\npipe_knn = Pipeline(steps=[\n    (\"preprocess\", preprocessor),                                # imputaci√≥n + escalado + one-hot\n    (\"knn\", KNeighborsClassifier())                              # modelo KNN sin hiperpar√°metros fijos\n])\n\n# Definimos una grilla razonable de hiperpar√°metros para Titanic\nparam_grid = {\n    \"knn__n_neighbors\": [3, 5, 7, 9, 11, 13, 15, 19, 25],       # distintos valores de k\n    \"knn__weights\": [\"uniform\", \"distance\"],                     # vecinos con peso igual o ponderado por distancia\n    \"knn__p\": [1, 2]                                             # p=1 (Manhattan), p=2 (Eucl√≠dea)\n}\n\n# Reutilizamos la misma validaci√≥n cruzada estratificada (5 folds, barajada, semilla fija)\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Configuramos el GridSearchCV\ngrid = GridSearchCV(\n    estimator=pipe_knn,                                          # pipeline completo\n    param_grid=param_grid,                                       # grilla de hiperpar√°metros\n    scoring=\"accuracy\",                                          # m√©trica de evaluaci√≥n (oficial de la comp)\n    cv=cv,                                                       # esquema de validaci√≥n\n    n_jobs=-1,                                                   # usar todos los cores disponibles\n    refit=True,                                                  # reentrena el mejor modelo con todo el train\n    verbose=1                                                    # mostrar progreso por consola\n)\n\n# Ejecutamos la b√∫squeda (entrena un modelo por cada combinaci√≥n de la grilla)\ngrid.fit(X, y)                                                   # ajusta sobre todo el train\n\n# Mostramos el mejor accuracy promedio en CV y la mejor combinaci√≥n de hiperpar√°metros\nprint(\"üîù Mejor accuracy (CV):\", grid.best_score_.round(4))       # mejor performance promedio\nprint(\"üîß Mejores hiperpar√°metros:\", grid.best_params_)           # diccionario con los mejores params\n\n# Guardamos el mejor estimador ya reentrenado (pipeline √≥ptimo listo para predecir)\nbest_model = grid.best_estimator_\n\n# Tabulamos los 5 mejores resultados para inspecci√≥n r√°pida\nresults = pd.DataFrame(grid.cv_results_).sort_values(\"mean_test_score\", ascending=False)\ncols = [\"mean_test_score\", \"std_test_score\", \"param_knn__n_neighbors\", \"param_knn__weights\", \"param_knn__p\"]\ntry:\n    display(results[cols].head(5))                               # display si est√° disponible (Kaggle/Notebook)\nexcept NameError:\n    print(results[cols].head(5))                                  # fallback a print si no existe display()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:17:26.265000Z","iopub.execute_input":"2025-08-28T04:17:26.265408Z","iopub.status.idle":"2025-08-28T04:17:28.591183Z","shell.execute_reply.started":"2025-08-28T04:17:26.265379Z","shell.execute_reply":"2025-08-28T04:17:28.590145Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 36 candidates, totalling 180 fits\nüîù Mejor accuracy (CV): 0.8238\nüîß Mejores hiperpar√°metros: {'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'uniform'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    mean_test_score  std_test_score param_knn__n_neighbors param_knn__weights  \\\n16         0.823803        0.015207                     11            uniform   \n8          0.822666        0.012162                      7            uniform   \n12         0.820438        0.011587                      9            uniform   \n20         0.815937        0.011984                     13            uniform   \n24         0.814808        0.008096                     15            uniform   \n\n   param_knn__p  \n16            1  \n8             1  \n12            1  \n20            1  \n24            1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>param_knn__n_neighbors</th>\n      <th>param_knn__weights</th>\n      <th>param_knn__p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>0.823803</td>\n      <td>0.015207</td>\n      <td>11</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.822666</td>\n      <td>0.012162</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.820438</td>\n      <td>0.011587</td>\n      <td>9</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.815937</td>\n      <td>0.011984</td>\n      <td>13</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.814808</td>\n      <td>0.008096</td>\n      <td>15</td>\n      <td>uniform</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# üì§ Celda 8 ‚Äî Entrenamiento final y creaci√≥n de `submission.csv`\nUsamos el **mejor pipeline** encontrado por GridSearchCV (`best_model`) para predecir en `test.csv` y generamos el archivo de env√≠o con las columnas `PassengerId` y `Survived`.","metadata":{}},{"cell_type":"code","source":"# best_model ya qued√≥ entrenado (refit=True) sobre todo el train al finalizar el Grid Search\n\n# 1) Predicciones sobre el set de test\ntest_preds = best_model.predict(X_test)        # obtiene 0/1 por pasajero\ntest_preds = test_preds.astype(int)            # aseguramos que sean enteros\n\n# 2) Construimos el DataFrame de submission (exactamente 2 columnas)\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_passenger_id,          # IDs del test en el mismo orden\n    \"Survived\": test_preds                     # predicciones binarias\n})\n\n# chequeo r√°pido de formato\nassert submission.shape[0] == 418, \"El submission debe tener exactamente 418 filas.\"\nassert list(submission.columns) == [\"PassengerId\", \"Survived\"], \"El submission debe tener dos columnas exactas.\"\n\n# 3) Guardamos el CSV listo para subir a Kaggle\nsubmission_file = \"submission.csv\"\nsubmission.to_csv(submission_file, index=False)\n\nprint(f\"‚úÖ Archivo '{submission_file}' creado con {submission.shape[0]} filas.\")\nprint(submission.head())\nprint(\"\\nConteo predicciones:\", submission['Survived'].value_counts().to_dict())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T04:20:19.510080Z","iopub.execute_input":"2025-08-28T04:20:19.510479Z","iopub.status.idle":"2025-08-28T04:20:19.572803Z","shell.execute_reply.started":"2025-08-28T04:20:19.510451Z","shell.execute_reply":"2025-08-28T04:20:19.571617Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Archivo 'submission.csv' creado con 418 filas.\n   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1\n\nConteo predicciones: {0: 263, 1: 155}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# üèÅ Resultado del Submission\n\n**Latest Score:** `0.76315` \n\n‚úÖ Este notebook corresponde a la versi√≥n **V2 (KNN con preprocesamiento + Grid Search)**.  \n","metadata":{}}]}